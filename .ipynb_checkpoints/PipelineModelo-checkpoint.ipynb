{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4dcd79-925b-4024-808f-8dde237e6d71",
   "metadata": {},
   "source": [
    "## 1. Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c655e5-00cc-43c1-a90f-1b9f7de8da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\leane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\leane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Instalación de librerias\n",
    "# librería Natural Language Toolkit, usada para trabajar con textos \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import re, unicodedata\n",
    "import contractions\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7a260-c584-42a3-9968-7f6b6a214e9a",
   "metadata": {},
   "source": [
    "## 2. Cargar datos iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d7fe19b-944a-4dd1-8e3c-2808ab8324a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargaDeFramework():\n",
    "    frameworkData = pd.read_csv('data/verifiedArticles.csv', sep=',', encoding = 'ANSI')\n",
    "    return frameworkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d5c7bf-cf2b-4d2d-a7ea-a3e5a1243a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargaDeScopus():    \n",
    "    scopusData = pd.read_csv('data/scopusArticles.csv', sep=',', encoding = 'utf-8')\n",
    "    return scopusData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17113d2-38eb-4e8a-bf60-b44f3cda853b",
   "metadata": {},
   "source": [
    "## 3. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebefbce2-e84f-46d1-9f46-3906e23bcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def delete_numbers(words):\n",
    "    \"\"\"Delete all interger occurrences in list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not word.isdigit():\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "        \n",
    "    \n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = delete_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0249fda8-b020-43ee-8e9f-43b16ba398db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = lemmatizer.lemmatize(word)\n",
    "        new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a8d9beb-d2df-424a-93f7-5b060ba35013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteriosACategorias(frameworkData):\n",
    "    frameworkData['Criterios'] = frameworkData['Criterios'].replace(['Alineación con la estrategia y objetivos', 'Selección', 'Priorización', 'Optimización'], 'Alineamiento estatégico')\n",
    "    frameworkData['Criterios'] = frameworkData['Criterios'].replace(['Papel de la analitica?', 'Gobierno del portafolio'], 'Manejo de gobernanza')\n",
    "    frameworkData['Criterios'] = frameworkData['Criterios'].replace(['Identificación de riesgos', 'Medición o cuantificación de riesgos'], 'Manejo de riesgo')\n",
    "    frameworkData['Criterios'] = frameworkData['Criterios'].replace(['Criterios para el monitoreo y medición de valor.', 'Criterios para establecer objetivos de valor'], 'Manejo de valor')\n",
    "    frameworkData['Criterios'] = frameworkData['Criterios'].replace(['Métricas para el monitoreo del portafolio de proyectos', 'KPI'], 'Monitoreo y control de portafolio')\n",
    "    frameworkData['Criterios'] = frameworkData['Criterios'].replace(['Gestión de intersados', 'Criterios para la medición de beneficios.', 'Gestión de capacidades', 'Criterios financieros para la selección de proyectos', 'Criterios financieros para la ejecución del portfolio '], 'Otros')\n",
    "    return frameworkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d5cdf41-0cc6-42d2-9f1e-a5a553d11a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizacionLematizacion(dataframe):\n",
    "    dataframe[\"Abstract\"] = dataframe[\"Abstract\"].apply(contractions.fix)\n",
    "    dataframe['Words'] = dataframe['Abstract'].apply(word_tokenize).apply(preprocessing)\n",
    "    dataframe['Words'] = dataframe['Words'].apply(lemmatize_verbs)\n",
    "    dataframe['Words'] = dataframe['Words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f9f7e9-2b82-4b5c-a2c7-b910da48658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminacionDeStopwords(dataframe, dataframeStopwords):\n",
    "    dataframe[\"Words\"] = dataframe[\"Words\"].replace('|'.join(dataframeStopwords), '', regex=True)\n",
    "    dataframe[\"Words\"] = dataframe[\"Words\"].replace(value='', regex=r'\\b(?!big)(?!dat)[a-z]{1,3}\\b')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f968f6fa-a2ba-47ea-a364-367959b4400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformacionDeFramework(frameworkData):\n",
    "    frameworkData = frameworkData[frameworkData[\"Criterios\"].notna()]\n",
    "    frameworkData = frameworkData[[\"Title\", \"Abstract\", \"Criterios\"]]\n",
    "    frameworkData['Abstract'] = frameworkData['Abstract'] + \" \" + frameworkData['Title']\n",
    "    criteriosACategorias(frameworkData)\n",
    "    tokenizacionLematizacion(frameworkData)\n",
    "    frameworkStopwords = [\"project\", \"portfolio\", \"help\", \"approach\", \"also\", \"new\", \"used\", \"management\", \"use\", \"time\", \"vrio\", \"aim\", \"could\", \"work\", \"order\", \"purpose\", \"making\", \"make\", \"related\", \"first\", \"towards\", \"role\", \"activity\", \"existing\", \"within\", \"one\", \"need\", \"organization\", \"current\", \"data\", \"paper\"]\n",
    "    eliminacionDeStopwords(frameworkData, frameworkStopwords)\n",
    "    return frameworkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "345541b4-d603-495e-9234-d166c60f4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformacionDeScopus(scopusData):\n",
    "    scopusData = scopusData[[\"Title\", \"Abstract\", \"Author Keywords\", \"Index Keywords\"]]\n",
    "    scopusData['Author Keywords'] = scopusData['Author Keywords'].fillna(\"\")\n",
    "    scopusData['Index Keywords'] = scopusData['Index Keywords'].fillna(\"\")\n",
    "    scopusData['Abstract'] = scopusData['Abstract'] + \" \" + scopusData['Title'] + \" \" + scopusData['Author Keywords'] + \" \" +  scopusData['Index Keywords']\n",
    "    scopusData = scopusData.drop(columns = ['Index Keywords', 'Author Keywords'])\n",
    "    tokenizacionLematizacion(scopusData)\n",
    "    scopusStopwords = [\"project\", \"portfolio\", \"develop\", \"approach\", \"system\", \"tool\", \"used\", \"team\", \"current\", \"activity\", \"structure\", \"present\", \"data\", \"need\", \"within\", \"open\", \"right\", \"time\", \"paper\", \"proceeding\", \"new\", \"different\", \"towards\", \"case\", \"topic\", \"based\"]\n",
    "    eliminacionDeStopwords(scopusData, scopusStopwords)\n",
    "    return scopusData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4ba75-6bbb-4207-8489-5ad96fc70f4a",
   "metadata": {},
   "source": [
    "## 4. Preparación de conjunto de datos preentrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d1b7499-704f-4a46-9ad6-ef7ee7bd005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearModeloFramework(frameworkData):\n",
    "    tfidfconverterF = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 2), encoding='latin-1', min_df=7, stop_words=('english'))\n",
    "    featuresF = tfidfconverterF.fit_transform(frameworkData.Words).toarray()\n",
    "    labels = frameworkData['Criterios']\n",
    "    smote = SMOTE(random_state=0, k_neighbors=1)\n",
    "    featuresSmote, labelsSmote = smote.fit_resample(featuresF, labels)\n",
    "    model = LinearSVC()\n",
    "    print(featuresSmote.shape)\n",
    "    model.fit(featuresSmote, labelsSmote);\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ad3ed-4065-46b0-bbf6-f45a4412ceb2",
   "metadata": {},
   "source": [
    "## 5. Predicción de etiquetas y actualización de datos entrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d277373-2acc-46a5-84aa-7d959f1923df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecirCategorias(scopusData, model):\n",
    "    tfidfconverterS = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 2), encoding='latin-1', min_df=380, stop_words=('english'))\n",
    "    featuresS = tfidfconverterS.fit_transform(scopusData.Words).toarray()\n",
    "    print(featuresS.shape)\n",
    "    scopusData[\"Criterios\"] = model.predict(featuresS)\n",
    "    return scopusData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae678e2-8cf7-4870-a414-712b03875ebe",
   "metadata": {},
   "source": [
    "## 6. Carga de predicción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea898d1-9603-4098-aa44-84118e8dcd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarPrediccion(scopusData):\n",
    "    scopusData.to_csv('data/classifiedScopusData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122c97d-5063-48de-9f7d-56ae59818f36",
   "metadata": {},
   "source": [
    "## 7. Ejecución de pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfebff5c-8bf1-4467-9a09-db91ddf42c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.24649292 0.         ... 0.         0.         0.28098211]\n",
      " [0.         0.         0.15290361 ... 0.         0.12723005 0.        ]\n",
      " [0.17022849 0.18575433 0.         ... 0.21960605 0.         0.        ]\n",
      " ...\n",
      " [0.28360093 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.23324442 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.31206137 0.         ... 0.21789671 0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leane\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\leane\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leane\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\leane\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\leane\\AppData\\Local\\Temp\\ipykernel_6200\\2091821024.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  scopusData['Author Keywords'] = scopusData['Author Keywords'].fillna(\"\")\n",
      "C:\\Users\\leane\\AppData\\Local\\Temp\\ipykernel_6200\\2091821024.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  scopusData['Index Keywords'] = scopusData['Index Keywords'].fillna(\"\")\n",
      "C:\\Users\\leane\\AppData\\Local\\Temp\\ipykernel_6200\\2091821024.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  scopusData['Abstract'] = scopusData['Abstract'] + \" \" + scopusData['Title'] + \" \" + scopusData['Author Keywords'] + \" \" +  scopusData['Index Keywords']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2382, 68)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'app\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m frameworkData \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m     cargaDeFramework()\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(criteriosACategorias)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(transformacionDeFramework)\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m modeloLinearSVC \u001b[38;5;241m=\u001b[39m crearModeloFramework(frameworkData)\n\u001b[0;32m      7\u001b[0m scopusData \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      8\u001b[0m     \u001b[43mcargaDeScopus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformacionDeScopus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredecirCategorias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodeloLinearSVC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcargarPrediccion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6142\u001b[0m, in \u001b[0;36mNDFrame.pipe\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   6140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m   6141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m common\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 6142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m common\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py:497\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m, in \u001b[0;36mcargarPrediccion\u001b[1;34m(scopusData)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcargarPrediccion\u001b[39m(scopusData):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mscopusData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapp/data/classifiedScopusData.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'app\\data'"
     ]
    }
   ],
   "source": [
    "frameworkData = (\n",
    "    cargaDeFramework()\n",
    "    .pipe(criteriosACategorias)\n",
    "    .pipe(transformacionDeFramework)\n",
    ")\n",
    "modeloLinearSVC = crearModeloFramework(frameworkData)\n",
    "scopusData = (\n",
    "    cargaDeScopus()\n",
    "    .pipe(transformacionDeScopus)\n",
    "    .pipe(predecirCategorias, model = modeloLinearSVC)\n",
    "    .pipe(cargarPrediccion)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a4390-fb1d-4847-8148-c83d3964127d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
